{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalProject_MaronPeeksWood.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6ppL4omvgle",
        "outputId": "e1231c1b-e160-47a7-8623-0a9c5bfc82d7"
      },
      "source": [
        "# Package imports and downloads\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Emoji is used to recognize and seperate emojis in the text\n",
        "!pip install emoji\n",
        "from emoji import UNICODE_EMOJI\n",
        "\n",
        "# flair package is used to assign a pos or neg sentiment for each tweet\n",
        "!pip3 install flair\n",
        "import flair\n",
        "flair_sentiment = flair.models.TextClassifier.load('en-sentiment')\n",
        "\n",
        "# Twint is used in the collection of data from twitter\n",
        "!pip3 install twint"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: flair in /usr/local/lib/python3.6/dist-packages (0.7)\n",
            "Requirement already satisfied: sentencepiece<=0.1.91 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.91)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.41.1)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair) (1.2.10)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (from flair) (5.8)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.7.0+cu101)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.7.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: transformers<=3.5.1,>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.5.1)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair) (1.5.10)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (from flair) (1.0.8)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3.2)\n",
            "Requirement already satisfied: janome in /usr/local/lib/python3.6/dist-packages (from flair) (0.4.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.6.2)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.11.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.18.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown->flair) (2.23.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (3.0.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (20.4)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (0.9.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (0.0.43)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (3.12.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (3.0.12)\n",
            "Requirement already satisfied: overrides==3.0.0 in /usr/local/lib/python3.6/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.0.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown->flair) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown->flair) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown->flair) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown->flair) (2020.11.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<=3.5.1,>=3.5.0->flair) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<=3.5.1,>=3.5.0->flair) (50.3.2)\n",
            "2020-12-07 17:58:59,320 loading file /root/.flair/models/sentiment-en-mix-distillbert_3.1.pt\n",
            "Requirement already satisfied: twint in /usr/local/lib/python3.6/dist-packages (2.1.20)\n",
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.6/dist-packages (from twint) (7.10.0)\n",
            "Requirement already satisfied: pysocks in /usr/local/lib/python3.6/dist-packages (from twint) (1.7.1)\n",
            "Requirement already satisfied: googletransx in /usr/local/lib/python3.6/dist-packages (from twint) (2.4.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from twint) (4.6.3)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.6/dist-packages (from twint) (0.1.11)\n",
            "Requirement already satisfied: schedule in /usr/local/lib/python3.6/dist-packages (from twint) (0.6.0)\n",
            "Requirement already satisfied: aiohttp-socks in /usr/local/lib/python3.6/dist-packages (from twint) (0.5.5)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.6/dist-packages (from twint) (2.1.7)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.6/dist-packages (from twint) (3.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from twint) (1.1.4)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.6/dist-packages (from twint) (1.17.0)\n",
            "Requirement already satisfied: aiodns in /usr/local/lib/python3.6/dist-packages (from twint) (2.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from elasticsearch->twint) (2020.11.8)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from elasticsearch->twint) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from googletransx->twint) (2.23.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp-socks->twint) (20.3.0)\n",
            "Requirement already satisfied: python-socks[asyncio]>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from aiohttp-socks->twint) (1.1.1)\n",
            "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (1.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (5.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (1.6.3)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->twint) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->twint) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->twint) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas->twint) (1.18.5)\n",
            "Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.6/dist-packages (from geopy->twint) (1.50)\n",
            "Requirement already satisfied: pycares>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from aiodns->twint) (3.1.1)\n",
            "Requirement already satisfied: typing; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiodns->twint) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->googletransx->twint) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->twint) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pycares>=3.0.0->aiodns->twint) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.5.0->pycares>=3.0.0->aiodns->twint) (2.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IZivyPfMu1T"
      },
      "source": [
        "# Data Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31soA-B0V1X1"
      },
      "source": [
        "DO NOT run unless you are gathering a new/different dataset to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcZIniN4M5KO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "bbd71a7b-a798-4470-a640-5de0f6af3c4b"
      },
      "source": [
        "# Python code to get data using twint, outputing to a file called 'output.csv'\n",
        "import csv, sys, twint\n",
        "\n",
        "#parse csv file\n",
        "usernames = []\n",
        "with open(sys.argv[1]) as csvfile:\n",
        "#    reader = csv.reader(csvfile, delimiter=\",\") \n",
        "#    next(reader)\n",
        "    for row in csvfile.readlines():\n",
        "        usernames.append(row.strip())\n",
        "\n",
        "print(\"Loaded %s usernames\" % len(usernames))\n",
        "\n",
        "length = len(usernames)\n",
        "\n",
        "#start scraping\n",
        "#create config\n",
        "c = twint.Config()\n",
        "c.Store_csv = True\n",
        "c.Hide_output = True\n",
        "c.Limit = 100\n",
        "for cur,username in enumerate(usernames[2323:]):\n",
        "    c.Username = username\n",
        "    c.Output = \"output/%s.csv\" % username\n",
        "    twint.run.Search(c)\n",
        "    print(\"Completed user %d/%d (%f%%)\" % (cur+1, length, float(cur+1)/float(length) * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-941cd3e2df77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Python code to get data using twint, outputing to a file called 'output.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#parse csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0musernames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'twint'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd5UVBAEUuSK"
      },
      "source": [
        "This section of code does not run in python, it runs in the go programming language to combine everything into one csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5giD9DkJNLpG"
      },
      "source": [
        "# This is code to combine tweets from all users gathered by Twint\n",
        "\n",
        "package main\n",
        "\n",
        "import (\n",
        "\t\"encoding/csv\"\n",
        "\t\"log\"\n",
        "\t\"os\"\n",
        "\t\"path/filepath\"\n",
        ")\n",
        "\n",
        "var inputPath = \"output/\"\n",
        "\n",
        "func main() {\n",
        "\t//open output\n",
        "\toutput, err := os.Create(\"output2.csv\")\n",
        "\tif err != nil {\n",
        "\t\tlog.Fatal(err)\n",
        "\t}\n",
        "\tdefer output.Close()\n",
        "\twriter := csv.NewWriter(output)\n",
        "\tstr := \"id,conversation_id,created_at,date,time,timezone,user_id,username,name,place,tweet,language,mentions,urls,photos,replies_count,retweets_count,likes_count,hashtags,cashtags,link,retweet,quote_url,video,thumbnail,near,geo,source,user_rt_id,user_rt,retweet_id,reply_to,retweet_date,translate,trans_src,trans_dest\"\n",
        "\toutput.Write([]byte(str + \"\\n\"))\n",
        "\n",
        "\t//walk input\n",
        "\terr = filepath.Walk(inputPath, func(path string, info os.FileInfo, err error) error {\n",
        "\t\tif err != nil {\n",
        "\t\t\treturn err\n",
        "\t\t}\n",
        "\n",
        "\t\tif !info.IsDir() {\n",
        "\t\t\tinput, err := os.Open(path)\n",
        "\t\t\tif err != nil {\n",
        "\t\t\t\treturn err\n",
        "\t\t\t}\n",
        "\t\t\treader := csv.NewReader(input)\n",
        "\n",
        "\t\t\treader.Read() // get rid of header\n",
        "\t\t\trecords, err := reader.ReadAll()\n",
        "\t\t\tif err != nil {\n",
        "\t\t\t\treturn err\n",
        "\t\t\t}\n",
        "\n",
        "\t\t\terr = writer.WriteAll(records)\n",
        "\t\t\tif err != nil {\n",
        "\t\t\t\treturn err\n",
        "\t\t\t}\n",
        "\n",
        "\t\t\tinput.Close()\n",
        "\t\t}\n",
        "\n",
        "\t\treturn nil\n",
        "\t})\n",
        "\tif err != nil {\n",
        "\t\tlog.Fatal(err)\n",
        "\t}\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y0_PWcQ_2nW"
      },
      "source": [
        "After the data has been gathered, the two classes are located in two seperate .csv files. Now we need to combine them into one csv file and add a column that tells us if each user is depressed or not depressed. A 1 represents the user is classified as depressed and a 0 represents not depressed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsz45w9Poh3G"
      },
      "source": [
        "# Combine the two depressed/nondepressed csv files into one data csv\n",
        "\n",
        "df = pd.read_csv('drive/Shareddrives/nlp term project/output.csv')\n",
        "df = df.drop(['id', 'conversation_id', 'created_at', 'timezone', 'user_id', \n",
        "         'place', 'language', 'photos', 'retweet', 'video', \n",
        "         'thumbnail', 'near', 'geo', 'source', 'user_rt_id',\n",
        "         'user_rt', 'retweet_id', 'retweet_date', 'translate',\n",
        "         'trans_src', 'trans_dest'], axis=1)\n",
        "df['depressed'] = 1\n",
        "\n",
        "df2 = pd.read_csv('drive/Shareddrives/nlp term project/output2.csv')\n",
        "df2 = df2.drop(['id', 'conversation_id', 'created_at', 'timezone', 'user_id', \n",
        "         'place', 'language', 'photos', 'retweet', 'video', \n",
        "         'thumbnail', 'near', 'geo', 'source', 'user_rt_id',\n",
        "         'user_rt', 'retweet_id', 'retweet_date', 'translate',\n",
        "         'trans_src', 'trans_dest'], axis=1)\n",
        "df2['depressed'] = 0\n",
        "\n",
        "df.drop(df.tail(147285).index, \n",
        "        inplace = True) \n",
        "\n",
        "\n",
        "print(len(pd.unique(df2['username'])))\n",
        "print(len(pd.unique(df['username'])))\n",
        "print(df['username'])\n",
        "\n",
        "df = df.append(df2, ignore_index=True)\n",
        "\n",
        "print()\n",
        "print()\n",
        "print(len(pd.unique(df['username'])))\n",
        "print(df)\n",
        "\n",
        "df.to_csv('drive/Shareddrives/nlp term project/depr_detect_data.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPDocfXMy8dg"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qifYrcKt7PrP",
        "outputId": "5b9d74bf-dd12-4d39-95bb-54ede00a22b5"
      },
      "source": [
        "# Load the full data from the csv format into a dataframe\n",
        "df = pd.read_csv('drive/Shareddrives/nlp term project/depr_detect_data.csv', lineterminator='\\n')\n",
        "df.head"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of               date      time  ... depressed sentiment\n",
              "0       2020-11-17  22:18:28  ...         1        -1\n",
              "1       2020-11-17  22:15:27  ...         1        -1\n",
              "2       2020-11-17  22:13:45  ...         1         1\n",
              "3       2020-11-17  22:10:45  ...         1         1\n",
              "4       2020-11-17  22:04:12  ...         1         1\n",
              "...            ...       ...  ...       ...       ...\n",
              "251680  2016-08-12  23:29:18  ...         0        -1\n",
              "251681  2020-11-17  17:09:23  ...         0        -1\n",
              "251682  2020-10-21  04:53:51  ...         0         1\n",
              "251683  2020-10-20  17:20:31  ...         0        -1\n",
              "251684  2020-10-14  18:18:12  ...         0        -1\n",
              "\n",
              "[251685 rows x 17 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP5gQ7JPAwLr"
      },
      "source": [
        "These functions are used to modify the tweet with some standard preprocessing steps used in text classification. Cast to lowercase, substitute any links, substitute user mentions, remove punctuation, remove stopwords, and lemmatize or stem the words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rEJMnJwk09U"
      },
      "source": [
        "# search your emoji\n",
        "def is_emoji(s):\n",
        "    return s in UNICODE_EMOJI\n",
        "\n",
        "# add space near your emoji\n",
        "def add_space(text):\n",
        "    return ''.join(' ' + char + ' ' if is_emoji(char) else char for char in text).strip()\n",
        "\n",
        "def preprocess_tweet_text(tweet):\n",
        "    tweet = tweet.lower()\n",
        "\n",
        "    tweet = add_space(tweet)\n",
        "\n",
        "    # Remove urls\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", 'LINK', tweet, flags=re.MULTILINE)\n",
        "    # Remove user @ references and '#' from tweet\n",
        "    tweet = re.sub(r'\\@\\w+|\\#','USER', tweet)\n",
        "    # Remove punctuations\n",
        "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove stopwords\n",
        "    tweet_tokens = word_tokenize(tweet)\n",
        "    filtered_words = [w for w in tweet_tokens if not w in stop_words]\n",
        "\n",
        "\n",
        "    #ps = PorterStemmer()\n",
        "    #stemmed_words = [ps.stem(w) for w in filtered_words]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemma_words = [lemmatizer.lemmatize(w, pos='a') for w in filtered_words]\n",
        "    \n",
        "    return \" \".join(lemma_words)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mG9sxtqBLok"
      },
      "source": [
        "Now store the preprocessed tweet seperately from the original tweet in the dataframe, sometimes the original texts is used to generate a feature so we don't want to modify them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n86iTGCelKZr",
        "outputId": "cff78088-a7cb-41c4-c9ee-b69cc3f008c2"
      },
      "source": [
        "# Preprocess and store the tweets \n",
        "df['processed_tweet'] = [preprocess_tweet_text(tweet) for tweet in df['tweet']]\n",
        "\n",
        "print(df[:50])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          date  ...                                    processed_tweet\n",
            "0   2020-11-17  ...                       day done time go home weep 😢\n",
            "1   2020-11-17  ...  USER good evening sad hear pls give family bes...\n",
            "2   2020-11-17  ...  USER triggers powerful beth never know take ef...\n",
            "3   2020-11-17  ...                        USER always welcome helen ☺\n",
            "4   2020-11-17  ...                                    USER know katie\n",
            "5   2020-11-17  ...  USER good evening annie trust fyne sooo sorry ...\n",
            "6   2020-11-17  ...           USER good evening toni men bad enemies 😕\n",
            "7   2020-11-17  ...  USER good evening chloe agree desperate times ...\n",
            "8   2020-11-17  ...                              USER chance teeth 😕 😂\n",
            "9   2020-11-17  ...       USER good night wendy safe peaceful nyte ☺ 😴\n",
            "10  2020-11-17  ...  USER gudnyt michele lily safe peaceful nyte du...\n",
            "11  2020-11-17  ...  USER dmd sorry hear gosh things becoming impos...\n",
            "12  2020-11-17  ...                   USER legend many reasons katie 😍\n",
            "13  2020-11-17  ...  USER good evening maryanne family hope well ne...\n",
            "14  2020-11-17  ...          USER good evening tamara found pls tell 😕\n",
            "15  2020-11-17  ...                  USER nyte jj family rest well ☺ 😴\n",
            "16  2020-11-17  ...  USER good evening toni may know worked civil s...\n",
            "17  2020-11-17  ...  USER good evening jj family hope fyne yes know...\n",
            "18  2020-11-17  ...  USER good evening john family trust fyne enjoy...\n",
            "19  2020-11-17  ...  USER good evening gosh sounds familiar small b...\n",
            "20  2020-11-17  ...  USER USER USER good evening jim family trust f...\n",
            "21  2020-11-17  ...                               USER neither wendy 😕\n",
            "22  2020-11-17  ...                                      USER genius 😍\n",
            "23  2020-11-17  ...  USER good evening rob trust fyne absolutely am...\n",
            "24  2020-11-17  ...  USER good evening wendy spk families autistic ...\n",
            "25  2020-11-17  ...          USER good evening trust fyne made laugh 😂\n",
            "26  2020-11-17  ...                         USER good evening beth day\n",
            "27  2020-11-17  ...  USER good evening wayne sorry hear stay strong...\n",
            "28  2020-11-17  ...  USER good evening chris woofers many happy ret...\n",
            "29  2020-11-17  ...  USER good evening nick good know getting prope...\n",
            "30  2020-11-17  ...  USER good evening maz family trust fyne deligh...\n",
            "31  2020-11-16  ...  world crazy beauty people people care going ta...\n",
            "32  2020-11-16  ...  USER sooo old 😕 series horror stories based wo...\n",
            "33  2020-11-16  ...                                    USER c la vie 😕\n",
            "34  2020-11-16  ...                                  USER USER welcome\n",
            "35  2020-11-16  ...                    USER good tnx adam tnx asking ☺\n",
            "36  2020-11-16  ...                        USER racism toxic many isms\n",
            "37  2020-11-16  ...                               USER worries david ☺\n",
            "38  2020-11-16  ...                                   USER hi jordan ☺\n",
            "39  2020-11-16  ...                         USER listening hear love 😍\n",
            "40  2020-11-16  ...                    USER excuse fuing disgraceful 😕\n",
            "41  2020-11-16  ...                                         USER yup 😕\n",
            "42  2020-11-16  ...                        USER hi luna wrong people 😕\n",
            "43  2020-11-16  ...                             USER economy screwed 😕\n",
            "44  2020-11-16  ...                   USER significant asking legend 😍\n",
            "45  2020-11-16  ...  USER intelligent person toni believe believe r...\n",
            "46  2020-11-16  ...  USER good evening donna family trust fyne fave...\n",
            "47  2020-11-16  ...                  USER attempted suicide cry 4 help\n",
            "48  2020-11-16  ...            USER easy katie symphony clean bandit 😍\n",
            "49  2020-11-16  ...                     USER matt hancock give break 😕\n",
            "\n",
            "[50 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrBq1qxkzBw2"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rUDj0FiB-aM"
      },
      "source": [
        "This part uses the flair package to assign a positive or negative sentiment label to each tweet in the dataset and then saves it to the csv file the data is stored in so that this does not have to be repeated every time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHTtbL50P_q3"
      },
      "source": [
        "DO NOT run unless you are spending the time to reassign sentiment value to every tweet in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i56aRE23zMlc"
      },
      "source": [
        "# Get sentiment using the Flair python package\n",
        "\n",
        "global counter\n",
        "counter = 0\n",
        "def get_sentiment(sentence):\n",
        "  global counter\n",
        "  counter = counter + 1\n",
        "  if counter % 10000 == 0:\n",
        "    print(counter)\n",
        "  if sentence == '':\n",
        "    return 1\n",
        "  s = flair.data.Sentence(sentence)\n",
        "  flair_sentiment.predict(s)\n",
        "  value = s.labels[0].to_dict()['value'] \n",
        "  if value == 'POSITIVE':\n",
        "    return 1\n",
        "  else:\n",
        "    return -1\n",
        "\n",
        "sentiments = [get_sentiment(tweet) for tweet in df['tweet']]\n",
        "df['sentiment'] = sentiments\n",
        "\n",
        "#df.to_csv('drive/Shareddrives/nlp term project/depr_detect_data.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZJ3KP-uCeak"
      },
      "source": [
        "Now we start the feature extraction and store all of the features in a dataframe matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFQykUk6YUw4",
        "outputId": "aad55f5f-c151-4d8e-bef7-df20b56e485e"
      },
      "source": [
        "# Create a dataframe to store the feature matrix\n",
        "features = pd.DataFrame()\n",
        "\n",
        "# Shows the count of unique usernames in the data\n",
        "usernames = pd.unique(df['username'])\n",
        "print(len(usernames))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o15kft6SO4dc"
      },
      "source": [
        "# Add the depression class assigned for each user as well as the proportions of \n",
        "# each users posts that are positive and negative \n",
        "depression_list = []\n",
        "positive_list = []\n",
        "negative_list = []\n",
        "\n",
        "for username in usernames:\n",
        "  depression_list.append(df[df.username == username].iloc[0]['depressed'])\n",
        "  positive_list.append(len(df[(df['username'] == username) & (df['sentiment'] == 1)]) / \n",
        "                       len(df[df['username'] == username]))\n",
        "  negative_list.append(len(df[(df['username'] == username) & (df['sentiment'] == -1)]) /\n",
        "                       len(df[df['username'] == username]))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP8pzEMRsIy0",
        "outputId": "f51197e5-e1ee-4370-e072-22214ef7f2fd"
      },
      "source": [
        "# Check that the features were properly added to the dataframe\n",
        "features['depressed'] = depression_list\n",
        "features['positive_prop'] = positive_list\n",
        "features['negative_prop'] = negative_list\n",
        "\n",
        "print(features)\n",
        "\n",
        "print(\"Average proportion of positive tweets per depressed user:\", features[features['depressed']==1].positive_prop.mean())\n",
        "print(\"Average proportion of positive tweets per nondepressed user:\", features[features['depressed']==0].positive_prop.mean())\n",
        "print(\"Average proportion of negative tweets per depressed user:\", features[features['depressed']==1].negative_prop.mean())\n",
        "print(\"Average proportion of negative tweets per nondepressed user:\", features[features['depressed']==0].negative_prop.mean())"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      depressed  positive_prop  negative_prop\n",
            "0             1       0.520000       0.480000\n",
            "1             1       0.350000       0.650000\n",
            "2             1       0.370000       0.630000\n",
            "3             1       0.390000       0.610000\n",
            "4             1       0.600000       0.400000\n",
            "...         ...            ...            ...\n",
            "2995          0       0.437500       0.562500\n",
            "2996          0       0.532468       0.467532\n",
            "2997          0       0.452381       0.547619\n",
            "2998          0       0.300000       0.700000\n",
            "2999          0       0.250000       0.750000\n",
            "\n",
            "[3000 rows x 3 columns]\n",
            "Average proportion of positive tweets per depressed user: 0.40642929006554945\n",
            "Average proportion of positive tweets per nondepressed user: 0.457781980778798\n",
            "Average proportion of negative tweets per depressed user: 0.5935707099344507\n",
            "Average proportion of negative tweets per nondepressed user: 0.5422180192212013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89ZKvnl6wqkn",
        "outputId": "48a9dbd8-3893-4df2-a54f-903bc46651d3"
      },
      "source": [
        "# Get the average swear words used per post for each user\n",
        "swears = \"fuck|shit|bitch|bullshit|effing|damn|goddamn|ass|bastard|dick\"\n",
        "\n",
        "# Total count of times a swear is in all tweets\n",
        "print(df.processed_tweet.str.count(swears).sum())\n",
        "\n",
        "swear_avgs = []\n",
        "for username in usernames:\n",
        "  swear_avgs.append(df[df['username'] == username].processed_tweet.str.count(swears).sum() / \n",
        "                    len(df[df['username'] == username]))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITzVCf6C1ZeR",
        "outputId": "693a5750-dc93-4fa8-e5f9-db157fd423ef"
      },
      "source": [
        "# Check that the feature was properly added to the dataframe\n",
        "features['swear_avgs'] = swear_avgs\n",
        "print(features)\n",
        "\n",
        "# Get the overall average swears per depressed or nondepressed classes\n",
        "dep_swears = df[df['depressed'] == 1].processed_tweet.str.count(swears).sum() / \\\n",
        "              len(df[df['depressed'] == 1])\n",
        "nondep_swears = df[df['depressed'] == 0].processed_tweet.str.count(swears).sum() / \\\n",
        "              len(df[df['depressed'] == 0])\n",
        "\n",
        "print('Average swear word count per tweet for all depressed users:', dep_swears)\n",
        "print('Average swear word count per tweet for all nondepressed users:', nondep_swears)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      depressed  positive_prop  negative_prop  swear_avgs\n",
            "0             1       0.520000       0.480000    0.000000\n",
            "1             1       0.350000       0.650000    0.050000\n",
            "2             1       0.370000       0.630000    0.060000\n",
            "3             1       0.390000       0.610000    0.050000\n",
            "4             1       0.600000       0.400000    0.000000\n",
            "...         ...            ...            ...         ...\n",
            "2995          0       0.437500       0.562500    0.000000\n",
            "2996          0       0.532468       0.467532    0.038961\n",
            "2997          0       0.452381       0.547619    0.035714\n",
            "2998          0       0.300000       0.700000    0.010000\n",
            "2999          0       0.250000       0.750000    0.000000\n",
            "\n",
            "[3000 rows x 4 columns]\n",
            "Average swear word count per tweet for all depressed users: 0.0752183785227728\n",
            "Average swear word count per tweet for all nondepressed users: 0.060564253604092386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PD5sHhPDJKO"
      },
      "source": [
        "This feature (Avg word count) ended up lowering the accuracy of the model so for now we decided to leave it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESFjdOYzSSp-"
      },
      "source": [
        "# Get a word count for each tweet in the data\n",
        "df['word_count'] = [len(tweet.split()) for tweet in df['tweet']]\n",
        "\n",
        "# Calculate the average word count for all the tweets a user has posted\n",
        "word_avgs = []\n",
        "for username in usernames:\n",
        "  word_avgs.append(df[df['username'] == username].word_count.sum() /\n",
        "                   len(df[df['username'] == username]))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ix6E0tQTrHQ",
        "outputId": "6ae7259c-aaba-46b4-ff0a-e6f240cd49cc"
      },
      "source": [
        "# Check that the feature is properly added to the dataframe\n",
        "features['word_count_avg'] = word_avgs\n",
        "print(features)\n",
        "\n",
        "# Calculate overall averages for each class\n",
        "print('Average word count per tweet for depressed users:', df[df['depressed'] == 1]['word_count'].mean())\n",
        "print('Average word count per tweet for nondepressed users:', df[df['depressed'] == 0]['word_count'].mean())\n",
        "\n",
        "# Ended up dropping this feature for now\n",
        "features = features.drop('word_count_avg', axis=1)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      depressed  positive_prop  negative_prop  swear_avgs  word_count_avg\n",
            "0             1       0.520000       0.480000    0.000000       13.700000\n",
            "1             1       0.350000       0.650000    0.050000        8.050000\n",
            "2             1       0.370000       0.630000    0.060000        9.820000\n",
            "3             1       0.390000       0.610000    0.050000        8.260000\n",
            "4             1       0.600000       0.400000    0.000000       15.970000\n",
            "...         ...            ...            ...         ...             ...\n",
            "2995          0       0.437500       0.562500    0.000000       12.687500\n",
            "2996          0       0.532468       0.467532    0.038961        9.467532\n",
            "2997          0       0.452381       0.547619    0.035714       14.523810\n",
            "2998          0       0.300000       0.700000    0.010000       13.700000\n",
            "2999          0       0.250000       0.750000    0.000000        3.000000\n",
            "\n",
            "[3000 rows x 5 columns]\n",
            "Average word count per tweet for depressed users: 15.275453452651263\n",
            "Average word count per tweet for nondepressed users: 11.49522554642691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eokcVGozUYn3",
        "outputId": "32c550de-d530-4521-a4d4-3e76c084d986"
      },
      "source": [
        "# Terms that could be used to describe symptoms in depression\n",
        "symptoms = \"anxiety|tired|tire|suicide|cry|sleep|sad|anger|frustrate|death|\"\\\n",
        "           \"irrit|feeling down|nervous|anxious|insomnia|cant sleep|hopeless|\"\\\n",
        "           \"dont care|stress|escape|procrastinate|pain|hurt|tear|angry|headache|\" \\\n",
        "           \"death|dead|worthless|restless|empty|no energy|not hungry|bored|failure|\" \\\n",
        "           \"hate|concentrate|memory|issues|nightmare|unhappy|miserable|\" \\\n",
        "           \"stress|no energy|ache|fail|help\"\n",
        "\n",
        "# Total count of times a symptom is mentioned in all tweets\n",
        "print(df.processed_tweet.str.count(symptoms).sum())\n",
        "\n",
        "# Calculate the average number of symptom mentions amongst all of a user's tweets\n",
        "symptom_avgs = []\n",
        "for username in usernames:\n",
        "  symptom_avgs.append(df[df['username'] == username].processed_tweet.str.count(symptoms).sum() / \n",
        "                    len(df[df['username'] == username]))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA3Iyxe8YhXl",
        "outputId": "c53d0e74-c27a-4c4d-a83c-265237114a78"
      },
      "source": [
        "# Check that the feature is properly added\n",
        "features['symptom_avgs'] = symptom_avgs\n",
        "print(features)\n",
        "\n",
        "# Get the overall averages of symptom mentions\n",
        "dep_sym = df[df['depressed'] == 1].processed_tweet.str.count(symptoms).sum() / \\\n",
        "              len(df[df['depressed'] == 1])\n",
        "nondep_sym = df[df['depressed'] == 0].processed_tweet.str.count(symptoms).sum() / \\\n",
        "              len(df[df['depressed'] == 0])\n",
        "\n",
        "print('Symptom mention average per tweet for depressed users:', dep_sym)\n",
        "print('Symptom mention average per tweet for nondepressed users:', nondep_sym)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      depressed  positive_prop  negative_prop  swear_avgs  symptom_avgs\n",
            "0             1       0.520000       0.480000    0.000000      0.050000\n",
            "1             1       0.350000       0.650000    0.050000      0.130000\n",
            "2             1       0.370000       0.630000    0.060000      0.090000\n",
            "3             1       0.390000       0.610000    0.050000      0.030000\n",
            "4             1       0.600000       0.400000    0.000000      0.050000\n",
            "...         ...            ...            ...         ...           ...\n",
            "2995          0       0.437500       0.562500    0.000000      0.000000\n",
            "2996          0       0.532468       0.467532    0.038961      0.090909\n",
            "2997          0       0.452381       0.547619    0.035714      0.095238\n",
            "2998          0       0.300000       0.700000    0.010000      0.090000\n",
            "2999          0       0.250000       0.750000    0.000000      0.000000\n",
            "\n",
            "[3000 rows x 5 columns]\n",
            "Symptom mention average per tweet for depressed users: 0.12158675036730332\n",
            "Symptom mention average per tweet for nondepressed users: 0.06538521159510154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pKP2FR3dsZd",
        "outputId": "46ee451a-2421-4120-9c66-5e5c118798b4"
      },
      "source": [
        "thirds = \"he|him|his|himself|she|her|herself|it|its|itself|oneself|they|them|their|themselves\"\n",
        "\n",
        "# Show the number of times a third person pronoun used among all tweets\n",
        "print(df.processed_tweet.str.count(thirds).sum())\n",
        "\n",
        "# Calculate the average number of 3rd person pronouns amongst all of a user's tweets\n",
        "third_person = []\n",
        "for username in usernames:\n",
        "  third_person.append(df[df['username'] == username].processed_tweet.str.count(thirds).sum() / \n",
        "                    len(df[df['username'] == username]))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "109999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvicB3z4j1rd",
        "outputId": "15e317c4-cdaf-42b9-e248-56e6cdf36a05"
      },
      "source": [
        "features['third_person'] = third_person\n",
        "print(features)\n",
        "\n",
        "# Get the overall averages of third person usages\n",
        "dep_third = df[df['depressed'] == 1].processed_tweet.str.count(thirds).sum() / \\\n",
        "              len(df[df['depressed'] == 1])\n",
        "nondep_third = df[df['depressed'] == 0].processed_tweet.str.count(thirds).sum() / \\\n",
        "              len(df[df['depressed'] == 0])\n",
        "\n",
        "print('Average number of third person pronouns per tweet for depressed users:', dep_third)\n",
        "print('Average number of third person pronouns per tweet for nondepressed users:', nondep_third)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      depressed  positive_prop  ...  symptom_avgs  third_person\n",
            "0             1       0.520000  ...      0.050000      0.220000\n",
            "1             1       0.350000  ...      0.130000      0.150000\n",
            "2             1       0.370000  ...      0.090000      0.240000\n",
            "3             1       0.390000  ...      0.030000      0.170000\n",
            "4             1       0.600000  ...      0.050000      0.290000\n",
            "...         ...            ...  ...           ...           ...\n",
            "2995          0       0.437500  ...      0.000000      0.750000\n",
            "2996          0       0.532468  ...      0.090909      0.311688\n",
            "2997          0       0.452381  ...      0.095238      0.476190\n",
            "2998          0       0.300000  ...      0.090000      0.410000\n",
            "2999          0       0.250000  ...      0.000000      0.000000\n",
            "\n",
            "[3000 rows x 6 columns]\n",
            "Average number of third person pronouns per tweet for depressed users: 0.46877521036463204\n",
            "Average number of third person pronouns per tweet for nondepressed users: 0.34500077507363197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAXAmHBHk92p",
        "outputId": "211b76dc-a9ff-4c52-9d31-3c9acd9c2b2d"
      },
      "source": [
        "firsts = \"I|me|my|mine|myself|we|us|our|ours|ourself\"\n",
        "\n",
        "# Show the number of times a first person pronoun used among all tweets\n",
        "print(df.processed_tweet.str.count(firsts).sum())\n",
        "\n",
        "# Calculate the average number of 1st person pronouns amongst all of a user's tweets\n",
        "first_person = []\n",
        "for username in usernames:\n",
        "  first_person.append(df[df['username'] == username].processed_tweet.str.count(firsts).sum() / \n",
        "                    len(df[df['username'] == username]))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "239536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4SalEaHk-Fv",
        "outputId": "ea62b7e9-a536-472d-8b1e-120ddc06a371"
      },
      "source": [
        "features['first_person'] = symptom_avgs\n",
        "print(features)\n",
        "\n",
        "# Get the overall averages of first person usages\n",
        "dep_first = df[df['depressed'] == 1].processed_tweet.str.count(firsts).sum() / \\\n",
        "              len(df[df['depressed'] == 1])\n",
        "nondep_first = df[df['depressed'] == 0].processed_tweet.str.count(firsts).sum() / \\\n",
        "              len(df[df['depressed'] == 0])\n",
        "\n",
        "print('Average number of first person pronouns per tweet for depressed users:', dep_first)\n",
        "print('Average number of first person pronouns per tweet for nondepressed users:', nondep_first)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      depressed  positive_prop  ...  third_person  first_person\n",
            "0             1       0.520000  ...      0.220000      0.050000\n",
            "1             1       0.350000  ...      0.150000      0.130000\n",
            "2             1       0.370000  ...      0.240000      0.090000\n",
            "3             1       0.390000  ...      0.170000      0.030000\n",
            "4             1       0.600000  ...      0.290000      0.050000\n",
            "...         ...            ...  ...           ...           ...\n",
            "2995          0       0.437500  ...      0.750000      0.000000\n",
            "2996          0       0.532468  ...      0.311688      0.090909\n",
            "2997          0       0.452381  ...      0.476190      0.095238\n",
            "2998          0       0.300000  ...      0.410000      0.090000\n",
            "2999          0       0.250000  ...      0.000000      0.000000\n",
            "\n",
            "[3000 rows x 7 columns]\n",
            "Average number of first person pronouns per tweet for depressed users: 1.0213383197542407\n",
            "Average number of first person pronouns per tweet for nondepressed users: 0.7497597271740816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1rmKjlmmPia"
      },
      "source": [
        "time_class = []\n",
        "# Find the most active time period for each user and store it as a value for each\n",
        "for username in usernames:\n",
        "  time_counts = [0,0,0,0,0,0]\n",
        "  times = df[df['username'] == username].time.str[:2]\n",
        "  for time in times:\n",
        "    time = int(time)\n",
        "    if time < 4:\n",
        "      time_counts[0] += 1\n",
        "    elif 4 <= time < 8:\n",
        "      time_counts[1] += 1\n",
        "    elif 8 <= time < 12:\n",
        "      time_counts[2] += 1\n",
        "    elif 12 <= time < 16:\n",
        "      time_counts[3] += 1\n",
        "    elif 16 <= time < 20:\n",
        "      time_counts[4] += 1\n",
        "    else:\n",
        "      time_counts[5] += 1\n",
        "  time_class.append(time_counts.index(max(time_counts)))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEu8ay2JrSuU",
        "outputId": "492cc985-0ac4-4eab-dd82-43bca135233c"
      },
      "source": [
        "# Check the feature is properly added\n",
        "features['active_time'] = time_class\n",
        "print(features)\n",
        "\n",
        "# Find the most frequent time period for users in each class\n",
        "print('Most active time period to post for depressed users:', \n",
        "      features[features['depressed'] == 1]['active_time'].mode())\n",
        "print('Most active time period to post for nondepressed users:',\n",
        "      features[features['depressed'] == 0]['active_time'].mode())\n",
        "\n",
        "# Since this feature has the same most active time period and does not affect model\n",
        "# accuracy, we can remove it for now\n",
        "features = features.drop('active_time', axis=1)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      depressed  positive_prop  ...  first_person  active_time\n",
            "0             1       0.520000  ...      0.050000            5\n",
            "1             1       0.350000  ...      0.130000            0\n",
            "2             1       0.370000  ...      0.090000            0\n",
            "3             1       0.390000  ...      0.030000            2\n",
            "4             1       0.600000  ...      0.050000            5\n",
            "...         ...            ...  ...           ...          ...\n",
            "2995          0       0.437500  ...      0.000000            4\n",
            "2996          0       0.532468  ...      0.090909            0\n",
            "2997          0       0.452381  ...      0.095238            4\n",
            "2998          0       0.300000  ...      0.090000            4\n",
            "2999          0       0.250000  ...      0.000000            4\n",
            "\n",
            "[3000 rows x 8 columns]\n",
            "Most active time period to post for depressed users: 0    4\n",
            "dtype: int64\n",
            "Most active time period to post for nondepressed users: 0    4\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QV-KVz6swfV"
      },
      "source": [
        "from datetime import date\n",
        "\n",
        "# Calculate the average time in days between each post for every user\n",
        "avg_days = []\n",
        "for username in usernames:\n",
        "  dates = df[df['username'] == username].date.str[:]\n",
        "  dates.reset_index(inplace=True, drop=True)\n",
        "  d0 = date(1,1,1)\n",
        "  #print(dates)\n",
        "  total = 0\n",
        "  for i in range(len(dates)):\n",
        "    tweet_date = dates[i].split('-')\n",
        "    year = int(tweet_date[0])\n",
        "    month = int(tweet_date[1])\n",
        "    day = int(tweet_date[2])\n",
        "    if i != 0:\n",
        "      d1 = date(year, month, day)\n",
        "      delta = d0 - d1\n",
        "      total += delta.days\n",
        "      d0 = date(year, month, day)\n",
        "    else:\n",
        "      d0 = date(year, month, day)\n",
        "  avg_days.append(total / len(df[df['username'] == username]))\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgpvQXOiuGtJ",
        "outputId": "b1faea96-4deb-4b0e-87a1-1658899cd971"
      },
      "source": [
        "# Check the feature is properly added\n",
        "features['avg_days'] = avg_days\n",
        "print(features)\n",
        "\n",
        "# Calculate the average number of days between tweets for each class\n",
        "print('Average number of days between posts for depressed users:',\n",
        "      features[features['depressed'] == 1]['avg_days'].mean())\n",
        "print('Average number of days between posts for nondepressed users:',\n",
        "      features[features['depressed'] == 0]['avg_days'].mean())"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      depressed  positive_prop  ...  first_person   avg_days\n",
            "0             1       0.520000  ...      0.050000   0.030000\n",
            "1             1       0.350000  ...      0.130000   2.740000\n",
            "2             1       0.370000  ...      0.090000   0.250000\n",
            "3             1       0.390000  ...      0.030000   0.480000\n",
            "4             1       0.600000  ...      0.050000   2.620000\n",
            "...         ...            ...  ...           ...        ...\n",
            "2995          0       0.437500  ...      0.000000  10.750000\n",
            "2996          0       0.532468  ...      0.090909   4.688312\n",
            "2997          0       0.452381  ...      0.095238   4.904762\n",
            "2998          0       0.300000  ...      0.090000  14.750000\n",
            "2999          0       0.250000  ...      0.000000   8.500000\n",
            "\n",
            "[3000 rows x 8 columns]\n",
            "Average number of days between posts for depressed users: 3.773596565507119\n",
            "Average number of days between posts for nondepressed users: 17.45462378761607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrDYLRQcWWcB"
      },
      "source": [
        "From expirimenting with the model and different features, we know that average word count and most active time period do not improve our model accuracy so we choose to use everything but those two for our models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIxgWk65XAHM"
      },
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdtVwOrwEFRz"
      },
      "source": [
        "Now that we have our features, we can create models and test their accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjgKUt0LzM0F",
        "outputId": "8ada73a2-c492-4742-ff08-1cc1dd5ec439"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "# Split the feature dataframe into training and test data\n",
        "train, test = train_test_split(features, test_size=0.2, random_state=50)\n",
        "\n",
        "# Create and display the X and Y sets to use for training and validation\n",
        "Xtrain = train.drop('depressed', axis=1)\n",
        "Ytrain = train['depressed'].values.tolist()\n",
        "\n",
        "Xtest = test.drop('depressed', axis=1)\n",
        "Ytest = test['depressed'].values.tolist()\n",
        "\n",
        "print(Xtrain)\n",
        "print(Ytrain)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      positive_prop  negative_prop  ...  first_person   avg_days\n",
            "1551       0.422535       0.577465  ...      0.056338  20.492958\n",
            "2568       0.470000       0.530000  ...      0.050000   0.930000\n",
            "1751       0.469072       0.530928  ...      0.087629   1.002577\n",
            "2851       1.000000       0.000000  ...      1.000000   0.000000\n",
            "1643       0.260000       0.740000  ...      0.060000   0.520000\n",
            "...             ...            ...  ...           ...        ...\n",
            "2014       0.571429       0.428571  ...      0.000000   7.428571\n",
            "2157       0.590000       0.410000  ...      0.040000  25.650000\n",
            "1931       0.833333       0.166667  ...      0.000000   0.333333\n",
            "1504       0.777778       0.222222  ...      0.000000  18.888889\n",
            "1712       0.800000       0.200000  ...      0.000000   0.114286\n",
            "\n",
            "[2400 rows x 7 columns]\n",
            "[0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0gt0qS45AbC",
        "outputId": "d952f746-43cc-41c1-d6ab-d5f5d980a2e5"
      },
      "source": [
        "# Create the random forest classifier from sklearn and fit \n",
        "# it to the data, using default values as tuning lowered accuracy\n",
        "\n",
        "clf = RandomForestClassifier(random_state=15)\n",
        "\n",
        "clf.fit(Xtrain, Ytrain)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=15, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "Wye8DF12MRx_",
        "outputId": "c4985f6e-923c-4a67-cabd-1520fe139f59"
      },
      "source": [
        "# Output various evaluation metrics for the random forest classifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "predictions = clf.predict(Xtest)\n",
        "print(classification_report(Ytest, predictions))\n",
        "print(\"Accuracy:\", accuracy_score(Ytest, predictions))\n",
        "print()\n",
        "print(confusion_matrix(Ytest, predictions))\n",
        "print()\n",
        "\n",
        "# display the confusion matrix as a proper plot\n",
        "disp = plot_confusion_matrix(clf, Xtest, Ytest, \n",
        "                             display_labels=['NonDepressed', 'Depressed'],\n",
        "                             cmap=plt.cm.binary, values_format='')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.76      0.80       309\n",
            "           1       0.77      0.85      0.81       291\n",
            "\n",
            "    accuracy                           0.81       600\n",
            "   macro avg       0.81      0.81      0.81       600\n",
            "weighted avg       0.81      0.81      0.81       600\n",
            "\n",
            "Accuracy: 0.8066666666666666\n",
            "\n",
            "[[236  73]\n",
            " [ 43 248]]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfiQWz6rVZ1Q",
        "outputId": "9a64b490-ee44-4228-fef4-9fec8b7818ea"
      },
      "source": [
        "# Create a neural network model on the features (from sklearn), it holds two layers\n",
        "# the second the same size as the number of features used\n",
        "clf2 = MLPClassifier(random_state=15, alpha=0.00001, hidden_layer_sizes=(100,7))\n",
        "\n",
        "clf2.fit(Xtrain, Ytrain)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100, 7), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=15, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "hgADIuFvV9m2",
        "outputId": "a87ece6d-ebfd-4eae-fe60-aa53185c4baf"
      },
      "source": [
        "# Output various evaluation metrics for the NN classifier\n",
        "predictions = clf2.predict(Xtest)\n",
        "print(classification_report(Ytest, predictions))\n",
        "print(\"Accuracy:\", accuracy_score(Ytest, predictions))\n",
        "print()\n",
        "print(confusion_matrix(Ytest, predictions))\n",
        "print()\n",
        "\n",
        "# display the confusion matrix as a proper plot\n",
        "disp = plot_confusion_matrix(clf2, Xtest, Ytest, \n",
        "                             display_labels=['NonDepressed', 'Depressed'],\n",
        "                             cmap=plt.cm.binary, values_format='')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.75      0.78       309\n",
            "           1       0.76      0.82      0.79       291\n",
            "\n",
            "    accuracy                           0.78       600\n",
            "   macro avg       0.78      0.78      0.78       600\n",
            "weighted avg       0.79      0.78      0.78       600\n",
            "\n",
            "Accuracy: 0.7833333333333333\n",
            "\n",
            "[[232  77]\n",
            " [ 53 238]]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}